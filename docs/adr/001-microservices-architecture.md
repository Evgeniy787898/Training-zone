# ADR-001: Микросервисная архитектура

**Статус:** Принято
**Дата:** 2025-12-06
**Авторы:** TZONA Team

## Контекст

Приложение TZONA начиналось как монолит (Node.js + Express). По мере роста функциональности появились следующие вызовы:
- AI Advisor требует Python для ML-библиотек
- Обработка изображений требует специализированных инструментов (Pillow, ImageMagick)
- Аналитика выполняет тяжёлые вычисления, блокирующие основной сервер

## Решение

Разделить систему на микросервисы:
- **backend** (Node.js/Express): API gateway, бизнес-логика, Telegram bot
- **ai-advisor** (Python/FastAPI): AI рекомендации, интеграция с OpenAI/Anthropic
- **image-processor** (Python/FastAPI): Обработка и оптимизация изображений
- **analytics** (Python/FastAPI): Статистика, агрегации, экспорт

Коммуникация через HTTP REST с graceful degradation при недоступности сервисов.

## Альтернативы

### Вариант A: Полный монолит
- **Плюсы:** Простота деплоя, нет network overhead
- **Минусы:** Нельзя использовать Python ML-библиотеки, блокировка при тяжёлых операциях
- **Почему отклонено:** AI функциональность критична для продукта

### Вариант B: Serverless (AWS Lambda / Vercel)
- **Плюсы:** Автоскейлинг, pay-per-use
- **Минусы:** Cold starts, vendor lock-in, сложность локальной разработки
- **Почему отклонено:** Требуется стабильная локальная среда разработки

## Последствия

### Положительные
- Независимый деплой каждого сервиса
- Использование лучших инструментов для каждой задачи
- Изоляция падений (один сервис не роняет всё)

### Отрицательные
- Сложность локального запуска (решается `start-with-ngrok.sh` и docker-compose)
- Network latency между сервисами
- Необходимость мониторинга нескольких процессов

## Связанные документы

- [docker-compose.yml](/docker-compose.yml)
- [start-with-ngrok.sh](/start-with-ngrok.sh)
- [ADR-002: Zod для валидации](./002-zod-validation.md)
